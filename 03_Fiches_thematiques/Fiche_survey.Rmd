# Utiliser des données d'enquêtes avec `R`

## Tâches concernées et recommandations

L'utilisateur souhaite utiliser des données d'enquête pour calculer des indicateurs ; en particulier, l'enjeu est d'utiliser la pondération des données d'enquête pour calculer de manière appropriée les indicateurs désirés.

::: {.recommandation data-latex=""}

* Pour le simple calcul nécessitant l'usage des pondérations, les _packages_ `stats` et `Hmisc` offrent l'essentiel des fonctions désirées;
* Pour des estimations qui prendrait en compte de manière formelle la théorie des sondages (en particulier pour l'estimation de la variance), il est conseillé d'utiliser le _package_ `survey`;
* Le package `survey` fonctionne dans des conditions particulières (plan de sondage simple, ou poids _bootstrap_). L'utilisateur pourra se référer au _package_ `gustave` pour les enquêtes de l'Insee;
* S'agissant de l'estimation économétrique, les fonctions d'estimation offrent généralement une option `weight`. Par ailleurs, le _package_ `survey` contient la fonction `svyglm` qui permet l'estimation des modèles les plus courants.

:::

## Pourquoi l'usage des données d'enquêtes est-il particulier?

::: {.conseil data-latex=""}

Ce paragraphe traite de considérations assez théoriques relatives aux données d'enquêtes et à leur usage. Il décrit en particulier la spécificité de ces données qui rend leur usage non trivial avec un logiciel statistique. Le lecteur intéressé par les aspects pratiques de l'estimation sur données d'enquêtes avec `R` peut à loisir se passer de la lecture de ce paragraphe.

:::

La spécificité des données d'enquêtes est qu'il s'agit de données granulaires, au sens où une observation va en réalité représenter un grand nombre d'unités statistiques. La théorie des sondages assure les propriétés statistiques des estimateurs dérivés des données d'enquêtes, et en particulier l'estimateur d'horwitz-Thompson $\sum_{s \in S}\frac{y_s}{\pi_s}$. L'utilisation des données pondérées ne va pas de soi, y compris dans un langage dédié à la statistique tel que `R` ; une des difficultés de l'estimation sur données pondérées est liée à la granularité des données, qui rend difficile la représentation de la fonction de distribution cumulative.

Pour rappel, la fonction de distribution cumulative, ou fonction de répartition, se formalise de la façon suivante : pour $x$ donné, elle s'écrit $F(x) = P(X \leq x)$. Or en présence de données granulaires, une grande partie des valeurs prises par $x$ ne sont pas connues (car l'information n'a pas été collectée), et il existe un grand nombre de méthodes pour estimer la valeur de la fonction de répartition dans cette situation. En conséquence, et de manière symétrique, il existe une grande variété de façons d'estimer un quantile, puisque le quantile se définit de la manière suivante : $Q(p) = F^{-1}(p) = inf\{x: F(x) \geq p\}$. En pratique, le quantile se calcule comme une interpolation pour les deux observations l'encadrant dans les données : ${\hat Q}(p) = (1-\gamma) X_{(j)} + \gamma X_{(j+1)}$. Toute la question est donc la forme que l'on donne à $\gamma$ ; la variété de choix de méthodes, déjà importante dans le cas non pondéré, est démultiplié dans le cas pondéré, comme le montre la documentation de la fonction `wtd.quantile` et en particulier le paramètre `type` du _package_ `Hmisc`. Pour plus de détails sur le calcul des quantiles dans les logiciels statistiques, se reporter à [l'article de Hyndman et Fan](https://www.amherst.edu/media/view/129116/original/Sample+Quantiles.pdf).

::: {.remarque data-latex=""}

Ces considérations ne sont pas propres au logiciel `R`. Ainsi, comme mis en évidence par l'article de Hyndman et Fan, `SAS` offre lui aussi des choix et opère un calcul par défaut. La question du passage de `SAS` à `R` rend alors cruciales ces considérations, l'enjeu étant de maintenir la continuité des méthodes de calcul.

:::

### Faire une estimation sur données pondérées

Le _package_ `Hmisc` fournit la boîte à outils la plus simple pour calculer divers indicateurs très classiques sur des données pondérées : moyenne, variance, quantile, rang. Il existe des _packages_ dédiés spécifiquement aux indicateurs d'inégalité (sujet très largement éclairé par les données d'enquête), tel le _package_ `laeken`, mais on s'apesantira ici uniquement sur les quelques indicateurs les plus classiques.

```{r, eval = FALSE}
library(Hmisc)
## table t, avec une variable quantitative y et une variable de poids p
with(t, wtd.mean(y, weights = p)) ## weighted mean
with(t, wtd.std(y, weights = p)) ## weighted standard deviation
with(t, wtd.quantile(y, weights = p, probs = 0.5, type = 'quantile'))  ## weighted median
```

Ne pas oublier d'expliquer ce qu'on obtient comme output.

Voici un second exemple de code, avec des options un peu plus avancées:

```{r, eval = FALSE}
output <- super_fonction(arguments et options)
```


### Réaliser la tâche, cas 2

Lorsqu'on est plus avancé, on peut utiliser la fonction `hyper_fonction()` du *package* `hyper_package`.

* Comportement par défaut;
* Principales options;
* Exemples de code.

## Quelques bonnes pratiques

Quelques conseils généraux sur la façon de s'y prendre.

* Faut-il préprocesser les données avant de réaliser la tâche;
* Comment minimiser les temps de calculs/la charge en RAM.

## Sources

Si le rédacteur de la fiche a réutilisé des ressources externes en français disponible en licence libre, il faut indiquer ici l'URL des ressources, le nom des auteurs et la licence de réutilisation de ces ressources.

## Ressources

* Sample Quantiles in Statistical Packages, R. J. Hyndman and Y. Fan, https://www.amherst.edu/media/view/129116/original/Sample+Quantiles.pdf
* les vignettes et *cheatsheets* si elles existent;
* les formations proposées par l'Insee;
* les formations/tutoriels disponibles sur internet.

Dans la mesure du possible, il faut veiller à proposer des ressources en français.
