# Restructurer des tables de données

## Tâches concernées et recommandations

Vous souhaitez restructurer vos tables de données depuis R en les pivotant selon une ou plusieurs variables (*long to wide* ou *wide to long*).

::: {.recommandation data-latex=""}

* Pour des tables de données de taille petite et moyenne (inférieure à 1 Go ou moins d'un million d'observations), **il est recommandé d'utiliser les _packages_ `tidyr` et `dplyr`** qui sont présentés en détail dans LA FICHE REFERENCE A COMPLETER;
* Pour des tables de données de grande taille (plus de 1 Go ou plus d'un million d'observations), **il est recommandé d'utiliser le *package* `data.table`** qui est présenté en détail dans la fiche [Manipuler des données avec `data.table`].
:::

<!--commGF : pas sûr que ce soit utile

## Présentation des concepts

Il est communément admis que le "nettoyage" et la préparation des données (*data cleaning*, *data munging*) représente une part importante du travail des professionnels du chiffre. On parle parfois d'un rapport "80/20" : 80% de préparation, 20% d'analyse. Parmi l'ensemble des opérations que ce champ recouvre, la restructuration des données tient une place importante. Les deux principales opérations de restructuration consistent à basculer d'un format dit **long** à un format **large**, ou inversement. On dit alors que l'on **pivote** les données, comme avec les tableaux croisés dynamiques d'`Excel ®`.

On trouve également dans la littérature les termes de *data.wrangling*, *reshaping*, *melt* (faire fondre), *cast* (jeter, lancer), *tidy / molten data*.

-->

## Principe de la restructuration des données

Une table de données stocke des informations sous forme de lignes et de colonnes. Au cours d'un traitement statistique, il est souvent nécessaire de restructurer les données, en transformant en colonnes certaines informations qui figuraient en ligne (ou inversement). Les deux principales opérations de restructuration des données peuvent être illustrées par les deux transformations suivantes:

- **Transformation *long to wide* **

![Transformation *long to wide*](./pics/datatable/longtowide.png)

- ** Transformation *wide to long** 

![Transformation *wide to long*](./pics/datatable/widetolong.png)


Cette fiche illustre les différentes méthodes de réorganisation des données avec les données de la Base Permanente des Equipements 2018 et les données du répertoire Filosofi 2016 agrégées au niveau communal, disponibles dans le package `doremifasol`:

```{r, eval=TRUE}
library(doremifasol)
bpe_ens_2018 <- bpe_ens_2018
filosofi_epci_2016 <- filosofi_epci_2016
```


## Restructurer des données avec le `tidyverse`

Cette section illustre les fonctions de restructuration de données avec le `tidyverse`.

```{r, echo = TRUE, message = FALSE, warning = FALSE}
library(tidyverse)
```

On commence par transformer les tables `bpe_ens_2018` et `filosofi_epci_2016` en `tibble`. Afin d'alléger la présentation, on conserve uniquement les variables sur le taux de pauvreté dans la table `filosofi_epci_2016`, et uniquement les données sur les boulangeries, les boucheries-charcuteries et les pharmacies ("B203", "B204" et "D301") dans la table `bpe_ens_2018`. Vous pouvez consulter la fiche [Manipuler des données avec le `tidyverse`] pour en apprendre davantage sur les objets `tibble`.

```{r, echo = TRUE}
# Convertir la table bpe_ens_2018 en tibble et sélectionner des observations
bpe_ens_2018_tbl <- as_tibble(bpe_ens_2018) %>% 
  filter(TYPEQU == "B203" | TYPEQU == "B204" | TYPEQU == "D301")

# Convertir la table filosofi_epci_2016 en tibble et sélectionner des variables
filosofi_epci_2016_tbl <- as_tibble(filosofi_epci_2016) %>% 
  select(CODGEO, TP6016, TP60AGE116, TP60AGE216,
         TP60AGE316, TP60AGE416, TP60AGE516, TP60AGE616)
```

#### `pivot_longer`: transformer des colonnes en lignes

La fonction `pivot_longer` permet de restructurer des données en transformant des colonnes en lignes. Elle sert fréquemment au début d'un traitement, pour transformer des données mal structurées en une table facile à traiter. Cette fonction prend quatre arguments principaux:

- le `data.frame` (ou le `tibble`) auquel elle est appliquée;
- `cols`: un vecteur contenant le nom des colonnes dont les valeurs vont être transposées;
- `names_to`: le nom de la nouvelle colonne qui va contenir les noms des colonnes transposées;
- `values_to`: le nom de la nouvelle colonne qui va contenir les valeurs des colonnes transposées.

Voici un exemple de l'usage de cette fonction avec les données Filosofi 2016 sur les EPCI. On peut voir que cette table contient deux types d'information: le code de l'EPCI (`CODGEO`), et des colonnes donnant le taux de pauvreté total (`TP6016`) et le taux de pauvreté par tranche d'âge (de `TP60AGE116` à `TP60AGE616`).

```{r}
filosofi_epci_2016_tbl
```

On restructure cette table avec la fonction `pivot_longer` pour obtenir une nouvelle table, avec une observation par EPCI et par tranche d'âge: on transpose les valeurs des colonnes dont le nom commence par "TP" (`cols = starts_with("TP")`), le nom des colonnes transposées sera indiquée dans la nouvelle colonne "tranche_age" (`names_to = "tranche_age"`) et les valeurs des colonnes transposées seront indiquées dans la colonne "taux_pauvrete" (`values_to = "taux_pauvrete"`).

```{r}
donnees_pauvrete_long <- filosofi_epci_2016_tbl %>% pivot_longer(cols = starts_with("TP"), names_to = "tranche_age", values_to = "taux_pauvrete")
donnees_pauvrete_long
```

#### `pivot_wider`: transformer des lignes en colonnes

La fonction `pivot_wider` permet de restructurer des données en transformant des lignes en colonnes. Cette fonction prend quatre arguments principaux:

- le `data.frame` (ou le `tibble`) auquel elle est appliquée;
- `id_cols`: un vecteur contenant le nom des colonnes qui définissent les observations de la table transposée;
- `names_from`: un vecteur contenant le nom de la (ou des) colonne(s) qui donne(nt) les noms des nouvelles colonnes;
- `values_from`: un vecteur contenant le nom de la (ou des) colonne(s) dont les valeurs vont être transposées.

Par ailleurs, il est souvent utile d'utiliser l'option `names_prefix` pour définir le préfixe du nom des nouvelles colonnes.

Voici un exemple de l'usage de cette fonction avec les données de la base permanente des équipements 2018. On peut voir que cette table contient une ligne par iris ou commune et par type d'équipement, ce qui explique qu'elle ait un grand nombre d'observations.

```{r}
bpe_ens_2018_tbl
```

On restructure cette table avec la fonction `pivot_wider` pour obtenir une nouvelle table avec l'iris ou la commune en ligne, et le nombre de boulangeries et le nombre de boucheries-charcuteries en colonnes: les lignes de la nouvelle table sont identifiées par l'identifiant d'iris (`id_cols = DCIRIS`), on transpose les valeurs contenues dans la colonne `NB_EQUIP` (`values_from = NB_EQUIP`), le nom des nouvelles colonnes transposées est indiqué dans la colonne `TYPEQU` (`names_from = TYPEQU`), et on choisit `NB_EQUIP_` comme préfixe pour le nom des nouvelles colonnes (`names_prefix = "NB_EQUIP_"`). On constate qu'il y a des valeurs manquantes dans la table de sortie car il arrive que certaines communes (ou certains iris) ne comptent aucun équipement de certains types.

```{r, eval=TRUE}
bpe_ens_2018_tbl %>%
	pivot_wider(id_cols = DCIRIS,  names_from = TYPEQU, values_from = NB_EQUIP, names_prefix = "NB_EQUIP_")
```


::: {.conseil data-latex=""}
Il est tentant de restructurer les données sous format *wide* car ce format peut paraître plus intuitif. Toutefois, il est généralement plus simple et plus rigoureux de traiter les données en format *long*. En effet, la restructuration de données sous format *wide* aboutit fréquemment à des tables mal ordonnées, dont les noms de colonnes contiennent des informations importantes. Il est donc conseillé de bien réfléchir avant de restructurer en format *wide*, et de ne le faire que lorsque cela paraît indispensable.
:::


## Restructurer des données avec `data.table`

### Pivoter des données vers un format large (*long to wide*)

La fonction `dcast` attend plusieurs paramètres :

+ `data` : désigne la table que l'on souhaite pivoter;
+ `formula` : une formule de type `ligne ~ colonne`;
+ `value.var` : la variable qui servira à alimenter le croisement ligne/colonne;
+ `fun.aggregate` : (FACULTATIF) la fonction d'agrégation à appliquer sur la `value.var`. Si les variables de `formula` n'identifient pas une valeur unique, la fonction `length` est utilisée par défaut.

Un exemple vaut mieux qu'un long discours :

```{r, echo = TRUE}
library(data.table)
knitr::kable(head(bpe_ens_2018))
```

Dans un premier temps, nous transformons notre table en `data.table` (si ce n'est pas déjà le cas)

```{r, echo = TRUE}
setDT(bpe_ens_2018)
# bpe2018_DT[, c("DC", "IRIS") := tstrsplit(DCIRIS, "_", fixed=TRUE)]
```

Supposons qu'on désire obtenir une table de contingence avec les modalités de la variable `REG` en colonnes (les codes régions) et celles de la variable `TYPEQU` en lignes (le type d'équipement). Au croisement lignes/colonnes, nous aurons les valeurs de la variable `NB_EQUIP`. Autrement dit, il s'agit de décomposer dans chaque région le nombre d'équipements en fonction du type. La première approche consiste à laisser l'argument par défaut pour `fun.aggregate`:

```{r, eval = TRUE}
head(
  data.table::dcast(data = bpe_ens_2018,
									formula = TYPEQU ~ REG,
									value.var = "NB_EQUIP")
)
```

Ici, la fonction `dcast` sans le paramètre `fun.aggregate` renvoie le nombre d'observations par croisement, comme le ferait l'instruction suivante :

```{r, eval=TRUE}
head(
  table(bpe_ens_2018$TYPEQU, bpe_ens_2018$REG)
  )
```

Ce comportement est dû au fait qu'**il n'y a pas qu'une seule valeur possible par croisement** lignes/colonnes. Lorsque une variable de poids existe (par exemple le nombre d'équipements concernés), cette approche fournit un tableau de contingence incorrect. 

En revanche, si nous ajoutons le paramètre `fun.aggregate`, le résultat est différent. Pour obtenir le tableau de contingence, c'es-o-dire la somme croisée des valeurs pour chaque "cellule" de la table, il convient d'ajouter l'argument de la manière suivante:

```{r, eval=TRUE}
head(
  data.table::dcast(data = bpe_ens_2018,
									formula = TYPEQU ~ REG,
									value.var = "NB_EQUIP",
									fun.aggregate = sum)
)
```

::: {.conseil data-latex=""}
Si l'on souhaite simplement concaténer les données dans une table, sans leur appliquer de traitement, il faut utiliser la fonction `toString`. 
<!----- Exemple pas top je trouve: je suis d'avis de le supprimer (pas très tidy)
Par exemple, supposons qu'on désire lister pour chaque IRIS (variable `DCIRIS`), le type d'équipement (variable `TYPEQU`) pour lequel plus 100 équipements sont disponibles :

```{r, eval=FALSE}
data.table::dcast(data = bpe_ens_2018[NB_EQUIP>100],
									formula = DCIRIS ~ TYPEQU,
									value.var = "NB_EQUIP",
									fun.aggregate = toString)
```
---->
:::

Il est également possible de calculer plusieurs indicateurs en même temps. Il faut alors préciser les fonctions dans une liste :

```{r, eval=FALSE}
head(
  data.table::dcast(data = bpe_ens_2018,
									formula = TYPEQU ~ REG,
									value.var = "NB_EQUIP",
									fun.aggregate = list(mean, sum))
)
```

<!--
il est également possible de passer sa propre fonction au paramètre `fun.aggregate` :

TODO : trouver un exemple pertinent de fonction

```{r, eval=FALSE}
data.table::dcast(data = warpDT,
									formula = tension ~ wool,
									value.var = "breaks",
									fun.aggregate = function(x) sum(x) / 2)
```

-->

### Pivoter des données vers un format long (*wide to long*)

La *"transposition"* des données en format long se réalise grâce à la fonction `melt`.

Les paramètres attendus sont :

+ `data` : désigne la table que l'on souhaite pivoter ;
+ `id.vars` : un vecteur de variable(s) "identifiante(s)". Ce sont les variables qui restent inchangées, c'est à dire qui ne seront pas transposées. Ce vecteur peut être composé soit d'entiers pour identifier les colonnes par leur index, soit de caractères pour sélectionner les colonnes par leur nom ;
+ `measure.vars` : la liste des colonnes à combiner ;
+ `variable.name` : nom de la colonne regroupant les `measure.vars` ;
+ `value.name` : nom de la colonne contenant la valeur pour chaque modalité de `variable.name`.

D'autres paramètres permettent de mieux contrôler le comportement de la fonction. Pour cela, consulter l'aide *via* `help(topic = "melt", package = "data.table)"`.

<!--
Pour illustrer cette fonction, nous utiliserons le jeu de données `VADeaths`, qui présente des taux de mortalités par genre et par type de territoire (rural / urbain). Pour les besoins de l'exemple, nous transformons préalablement ces données en objet de classe `data.table`.
-->

```{r, eval=TRUE}
VADeathsDT <- as.data.table(VADeaths, keep.rownames = TRUE)
knitr::kable(VADeathsDT)
```

Observons le comportement de la fonction si nous passons seulement le 1er paramètre `data`.

```{r, eval=TRUE}
head(
  data.table::melt(data = VADeathsDT),
  10
)
```

Nous pouvons constater que `data.table` a tenté de deviné la plupart des paramètres omis. Une façon plus correcte aurait été de préciser la valeur des paramètres, comme ceci :

```{r, eval=TRUE}
data.table::melt(data = VADeathsDT,
								 id.vars = "rn",
								 measure.vars = c(2:5),
								 variable.name = "indicateur",
								 value.name = "valeur")
```

Il est également possible de restructurer la table à partir d'une expression régulière (#ref vers fiche stringr) sur le nom des colonnes. Nous allons voir comment décomposer la table entre taux de mortalité par type de territoire en colonne (une colonne Rural hommes/femmes et une colonne Urbain hommes/femmes) :

```{r, eval=FALSE}
data.table::melt(data = VADeathsDT,
								 measure.vars = patterns("^Rural", "^Urban"),
								 value.name = c("Rural", "Urbain"))
```

::: {.conseil data-latex=""}
L'opération de *melting* permet notamment de représenter graphiquement les données (#GGPLOT2) avec `ggplot2`, qui nécessite ce type de structure de table.
:::


## A savoir

Il est possible que vous rencontriez, dans du codes transmis par vos collègues, des fonctions qui réalisent le même type de traitements. Notamment, les fonctions `reshape2::melt` et `reshape2::cast`.

La maintenance de ce `packages` n'étant plus assurée, il est recommandé de ne pas les utiliser dans vos futurs projets.

<!--commGF : pas sur qu'il est judicieux de donner un conseil qui peut causer des pb
Dans la mesure du possible, il serait souhaitable de les remplacer par celles présentées dans cette fiche (attention toutefois de ne pas briser des chaines de traitement).
-->

Les fonctions du *package* `tidyr` `pivot_longer` et `pivot_larger` ont récemment (en 2019) remplacé `gather` et `spread`. Il est donc possible de croiser ces termes dans des scripts qui n'auraient pas été mis à jour suite à l'évolution de ce *package*.

<!--
Le langage SQL permet également de réaliser ces opérations, notamment grâce à l'instruction `GROUP BY`. Enfin, le *package* `rpivotTable` permet de réaliser ce type de traitement de façon interactive en *drag and drop* avec la souris.
-->

## Pour aller plus loin {#RessourcesPIVOT}

On trouve sur internet beaucoup de ressources au sujet des opérations de restructuration de données :

* la [vignette du *package* `tidyr` sur le pivotage des données](https://cran.r-project.org/web/packages/tidyr/vignettes/pivot.html)
* la [traduction française de la cheatsheet sur `dplyr/tidyr`](https://github.com/rstudio/cheatsheets/raw/master/translations/french/data-wrangling-french.pdf);
* l'[article d'Hadley Wickham du *Journal of Statistical Sofware* (JSS) sur les données *tidy*](https://www.jstatsoft.org/article/view/v059i10);
* l'[équivalent pour le *package*; `data.table`](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reshape.html).



